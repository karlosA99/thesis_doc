\chapter{An\'alisis Experimental}\label{chapter:implementation}
En este cap\'itulo, se presenta el marco experimental dise\~nado para comprobar la efectividad del modelo de anotaci\'on 
descrito en el Cap\'itulo~\ref{chapter:proposal}, y la calidad del corpus generado. Se describen las configuraciones y 
par\'ametros utilizadas en el proceso de validaci\'on y evaluaci\'on. Adem\'as, se muestran los resultados obtenidos y 
se realiza un an\'alisis de los mismos.

\section{Marco Experimental}\label{section:experimental_framework}
El marco experimental dise\~nado tiene como objetivo evaluar la validez de la propuesta desarrollada. Se plantea 
una experimentaci\'on que permite comprobar si la soluci\'on cumple con los requisitos y restricciones establecidos inicialmente.
Para ello, se proporcionan especificaciones detalladas acerca del corpus utilizado y los escenarios de evaluaci\'on desarrollados.
Adem\'as, se describen los hiperpar\'ametros utilizados y el hardware empleado para la experimentaci\'on.

\subsection{Escenarios de Evaluaci\'on}
La experimentaci\'on realizada se divide en dos escenarios. El primero de ellos se centra en analizar la concordancia alcanzada entre 
los anotadores humanos durante el proceso de construcci\'on del corpus. El segundo escenario, se orienta a utilizar el corpus 
desarrollado para entrenar y evaluar la eficacia de un modelo de clasificaci\'on de g\'enero y raza. Esto tiene como objetivo determinar
la capacidad de un anotador autom\'atico en replicar de manera confiable las anotaciones realizadas por los humanos. 

\subsubsection{Escenario I: Concordancia entre Anotadores}\label{subsection:scenery1}
Este escenario tiene como objetivo examinar la concordancia entre anotadores planteada en la 
Secci\'on~\ref{subsection:annotation_evaluation}. El escenario busca obtener una estimaci\'on confiable de la dificultad de la 
tarea de anotaci\'on, as\'i como evaluar la calidad global de las anotaciones obtenidas. Esto se logra mediante la comparaci\'on
de las anotaciones realizadas de forma independiente por los dos anotadores no expertos, adem\'as de la comparaci\'on con la 
versi\'on final del corpus.

El an\'alisis de m\'etricas de concordancia inter-anotador permite determinar si las directrices propuestas en la 
Secci\'on~\ref{section:annotation_guidelines} fueron adecuadas. Tambi\'en verifica si el proceso dise\~nado logra generar
anotaciones consistentes entre distintos anotadores. Una alta concordancia respalda la validez del proceso de anotaci\'on
planteado.

Adicionalmente, se quiere evaluar la calidad que tendr\'ia un anotador autom\'atico de prop\'osito general. Para esto, se 
emplea \emph{ChatGPT}~3.5 como anotador autom\'atico, y se comparan sus anotaciones con el corpus final.

\subsubsection{Escenario II: Evaluaci\'on de Baselines}\label{subsection:scenery2}
Este escenario tiene como objetivo evaluar los baselines dise\~nados en la Secci\'on~\ref{section:baseline}, con el fin de 
validar su desempe\~no sobre el corpus desarrollado.

Para obtener los \emph{embeddings} de los textos utilizados en el proceso de entrenamiento del \emph{baseline} 
de aprendizaje autom\'atico, se utilizaron cuatro modelos de \emph{BERT} que ofrece \emph{HuggingFace}.
Por tanto se tienen cuatro conjuntos de \emph{embeddings} diferentes para el entrenamiento de cada uno de 
los modelos estudiados. La Tabla~\ref{table:bert_models} resume las arquitecturas de los modelos de \emph{BERT} utilizados.
De esta forma, se analiza el impacto de utilizar distintos modelos de \emph{BERT} para la representaci\'on 
sem\'antica de los textos sobre el desempe\~no de los \emph{baselines}. Los resultados obtenidos con cada 
combinaci\'on de modelo de \emph{BERT} y clasificador se reportan en la Secci\'on~\ref{section:results}.

\begin{table}[htpb]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lccc}
        \toprule
                \textbf{Modelo BERT} & \textbf{Par\'ametros} & \textbf{Dimensi\'on de Embeddings} & \textbf{Sensibilidad a May\'usculas}\\
                bert-base-uncased  & $110$M & $768$    & No\\
                bert-base-cased    & $110$M & $768$    & S\'i\\
                bert-large-uncased & $340$M & $1\,024$ & No\\
                bert-large-cased   & $340$M & $1\,024$ & S\'i\\
        \bottomrule
        \end{tabular}}
    \caption{Arquitecturas de modelos de \emph{BERT} utilizados.}
    \label{table:bert_models}
\end{table}

\subsubsection{M\'etricas de evaluaci\'on}
Las m\'etricas empleadas fueron macro precisi\'on, macro recobrado, macro $F_1$ y 
macro exactitud. Estas fueron calculadas apoy\'andose en las siguientes variables: 

\begin{itemize}
    \item \textbf{Anotaciones Positivas Correctas ($TP$)}: N\'umero de instancias positivas correctamente clasificadas.
    \item \textbf{Anotaciones Positivas Incorrectas ($FP$)}: N\'umero de instancias negativas clasificadas como positivas.
    \item \textbf{Anotaciones Negativas Correctas ($TN$)}: N\'umero de instancias negativas correctamente clasificadas.
    \item \textbf{Anotaciones Negativas Incorrectas ($FN$)}: N\'umero de instancias positivas clasificadas como negativas.
\end{itemize}

Las versiones macro de las m\'etricas se calculan promediando cada valor obtenido de las siguientes ecuaciones:

\begin{align}
    Precision_{attr} &= \frac{TP_{attr}}{TP_{attr} + FP_{attr}}\\
    Recobrado_{attr} &= \frac{TP_{attr}}{TP_{attr} + FN_{attr}}\\
    F1_{attr} &= 2 \cdot \frac{{Precision_{attr}} \cdot {Recobrado_{attr}}}{{Precision_{attr}} + {Recobrado_{attr}}}\\
    Exactitud_{multiclase} &= \frac{TP_{multiclase} + TN_{multiclase}}{TP_{multiclase} + TN_{multiclase} + FP_{multiclase} + FN_{multiclase}}\\
\end{align}


\subsection{Corpus de Evaluaci\'on}
El corpus utilizado para la experimentaci\'on corresponde al conjunto de $150$ textos con anotaciones de g\'enero y raza
generadas durante la construcci\'on del mismo, tal como se describe en la Secci\'on~\ref{section:annotation_process}.

Espec\'ificamente, para el Escenario~I~(\ref{subsection:scenery1}) se emplean las siguientes versiones del corpus:
\begin{itemize}
    \item Versi\'on 1: Conjunto de $150$ textos con las anotaciones realizadas por el anotador~1.
    \item Versi\'on 2: Conjunto de $150$ textos con las anotaciones realizadas por el anotador~2.
    \item Corpus Final: Versi\'on final del corpus de $150$ textos, luego del proceso de mezcla y revisi\'on por parte 
    del anotador experto.
\end{itemize}

La comparaci\'on entre estas tres versiones del corpus permite estimar de manera realista la concordancia entre los anotadores 
no expertos y la concordancia de cada uno de ellos con la versi\'on final revisada. 

En el Escenario~II~(\ref{subsection:scenery2}), se emplea la versi\'on final del corpus tanto para entrenar y evaluar el 
\emph{baseline} de aprendizaje autom\'atico, como para evaluar el \emph{baseline} humano.

Para llevar a cabo estas evaluaciones, se emplea la 
metodolog\'ia \emph{K-fold cross-validation}. En este proceso, el modelo se entrena $K$ veces, utilizando 
$K-1$ particiones del corpus como conjunto de entrenamiento y la partici\'on restante como conjunto de evaluaci\'on.
Este enfoque permite obtener m\'etricas de rendimiento m\'as robustas y confiables, teniendo en cuenta 
la limitada cantidad de datos disponibles.

Para ambos \emph{baselines}, se elimina una fila del corpus. La raz\'on detr\'as de esto es que el atributo raza de dicha 
fila conten\'ia la \'unica instancia de la clase \emph{Native American} en el corpus. 
Esto genera conflictos durante el proceso de validaci\'on cruzada, ya que idealmente deber\'ian existir al menos dos 
instancias de cada clase en el corpus.

\subsection{Hiperpar\'ametros}
En el proceso de entrenamiento y evaluaci\'on de ambos \emph{baselines} el par\'ametro de la t\'ecnica de validaci\'on
cruzada se fija en $K=5$. 

\subsection{Hardware}
Los experimentos fueron ejecutados en un equipo con las siguientes propiedades: 4 n\'ucleos de CPU \emph{Intel(R) Core(TM)} i7-6700K
@ 4.00GHz de velocidad con 8 MB de cach\'e y 16 GB de RAM DDR4 a una velocidad de 3200MHz.

El sistema operativo utilizado fue \emph{Windows 10 Pro}, versi\'on 21H2 y con una arquitectura de 64 bits.

\section{Resultados}\label{section:results}
A continuaci\'on se muestran los resultados obtenidos a partir de realizar los experimentos descritos en la 
Secci\'on~\ref{section:experimental_framework}.

La Tabla~\ref{table:agreement_humans} y la Tabla~\ref{table:agreement_gpt} muestran los resultados del 
Escenario~I~(\ref{subsection:scenery1}).
Estas tablas resumen los resultados de las m\'etricas de concordancia calculadas entre las distintas
versiones del corpus y el anotador autom\'atico \emph{ChatGPT}~3.5, respectivamente. En ellas, se 
calcula para los conjuntos $C_{g\acute{e}nero}$, $C_{raza}$ y $C_{g\acute{e}nero, raza}$ definidos
en la Secci\'on~\ref{subsection:annotation_evaluation} las m\'etricas: media, varianza y desviaci\'on
est\'andar. Adem\'as, se calcula el \emph{macro-agreement} definido en dicha secci\'on.

\begin{table}[htpb]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{llccc}
        \toprule
        \textbf{M\'etrica de concordancia} &&\textbf{Ver. 1 - Ver. 2} & \textbf{Ver. 1 - Final} & \textbf{Ver. 2 - Final} \\
        \midrule
        \midrule
        \multirow{3}{*}{G\'enero} & $\mu C_{g\acute{e}nero}$                & 0.873 & 0.917 & 0.943\\
        \cmidrule{2-5}
                                  & $\sigma C_{g\acute{e}nero}$             & 0.324 & 0.268 & 0.228\\
        \cmidrule{2-5}
                                  & $\sigma^2 C_{g\acute{e}nero}$           & 0.105 & 0.072 & 0.052\\
        \midrule\midrule
        \multirow{3}{*}{Raza}     & $\mu C_{raza}$                          & 0.898 & 0.917 & 0.981\\
        \cmidrule{2-5}
                                  & $\sigma C_{raza}$                       & 0.279 & 0.256 & 0.124\\
        \cmidrule{2-5}
                                  & $\sigma^2 C_{raza}$                     & 0.078 & 0.066 & 0.015\\
        \midrule\midrule
        \multirow{4}{*}{General}  & $\mu C_{g\acute{e}nero, raza}$          & 0.870 & 0.903 & 0.956\\
        \cmidrule{2-5}
                                  & $\sigma C_{g\acute{e}nero, raza}$       & 0.263 & 0.232 & 0.173\\
        \cmidrule{2-5}
                                  & $\sigma^2 C_{g\acute{e}nero, raza}$     & 0.069 & 0.054 & 0.030\\
        \cmidrule{2-5}
                                  & Macro Agr.                              & 0.886 & 0.917 & 0.962\\
        \bottomrule
        \end{tabular}}
    \caption{Resumen de m\'etricas de concordancia entre las distintas versiones del corpus.}
    \label{table:agreement_humans}
\end{table}

\begin{table}[htpb]
    \centering
    \resizebox{0.75\textwidth}{!}{
        \begin{tabular}{llc}
        \toprule
        \textbf{M\'etrica de concordancia} &&\textbf{ChatGPT - Final} \\
        \midrule
        \midrule
        \multirow{3}{*}{G\'enero} & $\mu C_{g\acute{e}nero}$                & 0.350\\
        \cmidrule{2-3}
                                  & $\sigma C_{g\acute{e}nero}$             & 0.455\\
        \cmidrule{2-3}
                                  & $\sigma^2 C_{g\acute{e}nero}$           & 0.207\\
        \midrule\midrule
        \multirow{3}{*}{Raza}     & $\mu C_{raza}$                          & 0.371\\
        \cmidrule{2-3}
                                  & $\sigma C_{raza}$                       & 0.475\\
        \cmidrule{2-3}
                                  & $\sigma^2 C_{raza}$                     & 0.225\\
        \midrule\midrule
        \multirow{4}{*}{General}  & $\mu C_{g\acute{e}nero, raza}$          & 0.329\\
        \cmidrule{2-3}
                                  & $\sigma C_{g\acute{e}nero, raza}$       & 0.352\\
        \cmidrule{2-3}
                                  & $\sigma^2 C_{g\acute{e}nero, raza}$     & 0.124\\
        \cmidrule{2-3}
                                  & Macro Agr.                              & 0.361\\
        \bottomrule
        \end{tabular}}
    \caption{Resumen de m\'etricas de concordancia entre \emph{ChatGPT} y el corpus final.}
    \label{table:agreement_gpt}
\end{table}

En cuanto al Escenario~II~(\ref{subsection:scenery2}), la Tabla~\ref{table:eval_baselines_gender} y la Tabla~\ref{table:eval_baselines_race}
muestran las m\'etricas alcanzadas por el \emph{baseline} de aprendizaje autom\'atico y el \emph{baseline} humano en las tareas de 
predicci\'on de los atribuitos g\'enero y raza respectivamente. Para el \emph{baseline} de aprendizaje autom\'atico se presentan 
los resultados considerando diversas combinaciones entre los modelos de \emph{BERT} utilizados para obtener los 
\emph{embeddings} de los textos, y los modelos de clasificaci\'on evaluados. 

% Por otro lado, en la Tabla~\ref{table:eval_baseline2_gender} y la Tabla~\ref{table:eval_baseline2_race} se detallan
% los resultados del \emph{baseline} humano en la misma tarea de predicci\'on de g\'enero y raza. 

% \begin{table}[htpb]
%     \centering
%     \resizebox{\textwidth}{!}{
%         \begin{tabular}{llcccc}
%         \toprule
%         \textbf{Combinaci\'on de Modelos} &&\textbf{Precisi\'on} & \textbf{Recobrado} & \textbf{F1} & \textbf{Exactitud}\\
%         \midrule
%         \midrule
%         \multirow{4}{*}{bert-base-uncased}  & \emph{Logistic Regression}  & 0.740 & 0.788 & 0.757 & 0.366\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.695 & 0.816 & 0.744 & 0.308\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.671 & 0.867 & 0.749 & 0.302\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.733 & 0.788 & 0.753 & 0.375\\
%         \midrule\midrule
%         \multirow{4}{*}{bert-base-cased}    & \emph{Logistic Regression}  & 0.707 & 0.768 & 0.732 & 0.356\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.673 & 0.718 & 0.689 & 0.300\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.621 & 1.000 & 0.764 & 0.257\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.743 & 0.734 & 0.727 & 0.387\\
%         \midrule\midrule
%         \multirow{4}{*}{bert-large-uncased} & \emph{Logistic Regression}  & 0.707 & 0.787 & 0.741 & 0.366\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.684 & 0.771 & 0.719 & 0.343\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.617 & 1.000 & 0.761 & 0.250\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.695 & 0.751 & 0.718 & 0.404\\
%         \midrule\midrule
%         \multirow{4}{*}{bert-large-cased}   & \emph{Logistic Regression}  & 0.713 & 0.790 & 0.744 & 0.366\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.691 & 0.739 & 0.709 & 0.319\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.639 & 0.848 & 0.722 & 0.275\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.725 & 0.755 & 0.728 & 0.345\\
%         \bottomrule
%         \end{tabular}}
%     \caption{Resumen de m\'etricas de evaluaci\'on del \emph{baseline} de aprendizaje autom\'atico en cuanto a la predicci\'on del atributo g\'enero.}
%     \label{table:eval_baseline1_gender}
% \end{table}

\begin{table}[htpb]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{llcccc}
        \toprule
        \textbf{Combinaci\'on de Modelos} &&\textbf{Precisi\'on} & \textbf{Recobrado} & \textbf{F1} & \textbf{Exactitud}\\
        \midrule
        \midrule
        \multirow{4}{*}{bert-base-uncased}  & \emph{Logistic Regression}  & 0.740 & 0.788 & 0.757 & 0.366\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.695 & 0.816 & 0.744 & 0.308\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.671 & 0.867 & 0.749 & 0.302\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.733 & 0.788 & 0.753 & 0.375\\
        \midrule\midrule
        \multirow{4}{*}{bert-base-cased}    & \emph{Logistic Regression}  & 0.707 & 0.768 & 0.732 & 0.356\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.673 & 0.718 & 0.689 & 0.300\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.621 & 1.000 & 0.764 & 0.257\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.743 & 0.734 & 0.727 & 0.387\\
        \midrule\midrule
        \multirow{4}{*}{bert-large-uncased} & \emph{Logistic Regression}  & 0.707 & 0.787 & 0.741 & 0.366\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.684 & 0.771 & 0.719 & 0.343\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.617 & 1.000 & 0.761 & 0.250\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.695 & 0.751 & 0.718 & 0.404\\
        \midrule\midrule
        \multirow{4}{*}{bert-large-cased}   & \emph{Logistic Regression}  & 0.713 & 0.790 & 0.744 & 0.366\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.691 & 0.739 & 0.709 & 0.319\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.639 & 0.848 & 0.722 & 0.275\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.725 & 0.755 & 0.728 & 0.345\\
        \midrule\midrule
        \multirow{2}{*}{Modelo Humano}      & \emph{Anotaci\'on 1}        & 0.937 & 1.000 & 0.967 & 0.872\\
        \cmidrule{2-6}
                                            & \emph{Anotaci\'on 2}        & 1.000 & 0.947 & 0.971 & 0.957\\
        \bottomrule
        \end{tabular}}
    \caption{Resumen de las m\'etricas de evaluaci\'on del \emph{baseline} de aprendizaje autom\'atico y el \emph{baseline} humano 
    en cuanto a la predicci\'on del atributo g\'enero.}
    \label{table:eval_baselines_gender}
\end{table}

\begin{table}[htpb]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{llcccc}
        \toprule
        \textbf{Combinaci\'on de Modelos} &&\textbf{Precisi\'on} & \textbf{Recobrado} & \textbf{F1} & \textbf{Exactitud}\\
        \midrule
        \midrule
        \multirow{4}{*}{bert-base-uncased}  & \emph{Logistic Regression}  & 0.153 & 0.142 & 0.143 & 0.177\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.141 & 0.132 & 0.133 & 0.192\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.098 & 0.165 & 0.123 & 0.132\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.162 & 0.151 & 0.154 & 0.186\\
        \midrule\midrule
        \multirow{4}{*}{bert-base-cased}    & \emph{Logistic Regression}  & 0.158 & 0.147 & 0.148 & 0.179\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.114 & 0.136 & 0.124 & 0.151\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.097 & 0.167 & 0.123 & 0.129\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.181 & 0.188 & 0.177 & 0.205\\
        \midrule\midrule
        \multirow{4}{*}{bert-large-uncased} & \emph{Logistic Regression}  & 0.112 & 0.119 & 0.115 & 0.155\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.100 & 0.113 & 0.106 & 0.149\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.097 & 0.167 & 0.123 & 0.129\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.124 & 0.117 & 0.118 & 0.171\\
        \midrule\midrule
        \multirow{4}{*}{bert-large-cased}   & \emph{Logistic Regression}  & 0.124 & 0.138 & 0.129 & 0.188\\
        \cmidrule{2-6}
                                            & \emph{Random Forest}        & 0.110 & 0.123 & 0.116 & 0.151\\
        \cmidrule{2-6}
                                            & \emph{SVC}                  & 0.098 & 0.167 & 0.123 & 0.132\\
        \cmidrule{2-6}
                                            & \emph{MLP}                  & 0.119 & 0.112 & 0.111 & 0.170\\
        \midrule\midrule
        \multirow{2}{*}{Modelo Humano}      & \emph{Anotaci\'on 1}        & 0.816 & 0.815 & 0.803 & 0.810\\
        \cmidrule{2-6}
                                            & \emph{Anotaci\'on 2}        & 0.900 & 0.878 & 0.886 & 0.959\\
        \bottomrule
        \end{tabular}}
    \caption{Resumen de las m\'etricas de evaluaci\'on del \emph{baseline} de aprendizaje autom\'atico y el \emph{baseline} humano 
    en cuanto a la predicci\'on del atributo raza.}
    \label{table:eval_baselines_race}
\end{table}

% \begin{table}[htpb]
%     \centering
%     \resizebox{\textwidth}{!}{
%         \begin{tabular}{llcccc}
%         \toprule
%         \textbf{Combinaci\'on de Modelos} &&\textbf{Precisi\'on} & \textbf{Recobrado} & \textbf{F1} & \textbf{Exactitud}\\
%         \midrule
%         \midrule
%         \multirow{4}{*}{bert-base-uncased}  & \emph{Logistic Regression}  & 0.153 & 0.142 & 0.143 & 0.177\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.141 & 0.132 & 0.133 & 0.192\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.098 & 0.165 & 0.123 & 0.132\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.162 & 0.151 & 0.154 & 0.186\\
%         \midrule\midrule
%         \multirow{4}{*}{bert-base-cased}    & \emph{Logistic Regression}  & 0.158 & 0.147 & 0.148 & 0.179\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.114 & 0.136 & 0.124 & 0.151\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.097 & 0.167 & 0.123 & 0.129\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.181 & 0.188 & 0.177 & 0.205\\
%         \midrule\midrule
%         \multirow{4}{*}{bert-large-uncased} & \emph{Logistic Regression}  & 0.112 & 0.119 & 0.115 & 0.155\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.100 & 0.113 & 0.106 & 0.149\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.097 & 0.167 & 0.123 & 0.129\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.124 & 0.117 & 0.118 & 0.171\\
%         \midrule\midrule
%         \multirow{4}{*}{bert-large-cased}   & \emph{Logistic Regression}  & 0.124 & 0.138 & 0.129 & 0.188\\
%         \cmidrule{2-6}
%                                             & \emph{Random Forest}        & 0.110 & 0.123 & 0.116 & 0.151\\
%         \cmidrule{2-6}
%                                             & \emph{SVC}                  & 0.098 & 0.167 & 0.123 & 0.132\\
%         \cmidrule{2-6}
%                                             & \emph{MLP}                  & 0.119 & 0.112 & 0.111 & 0.170\\
%         \bottomrule
%         \end{tabular}}
%     \caption{Resumen de m\'etricas de evaluaci\'on del \emph{baseline} de aprendizaje autom\'atico en cuanto a la predicci\'on del atributo raza.}
%     \label{table:eval_baseline1_race}
% \end{table}

% \begin{table}[htpb]
%     \centering
%     \resizebox{0.75\textwidth}{!}{
%         \begin{tabular}{lcccc}
%         \toprule
%         \textbf{Modelo} &\textbf{Precisi\'on} & \textbf{Recobrado} & \textbf{F1} & \textbf{Exactitud}\\
%         \midrule
%         \midrule
%                        {Anotaci\'on 1}      & 0.937 & 1.000 & 0.967 & 0.872\\
%                        {Anotaci\'on 2}      & 1.000 & 0.947 & 0.971 & 0.957\\
%         \bottomrule
%         \end{tabular}}
%     \caption{Resumen de m\'etricas de evaluaci\'on del \emph{baseline} humano en cuanto a la predicci\'on del atributo g\'enero.}
%     \label{table:eval_baseline2_gender}
% \end{table}

% \begin{table}[htpb]
%     \centering
%     \resizebox{0.75\textwidth}{!}{
%         \begin{tabular}{lcccc}
%         \toprule
%         \textbf{Modelo} &\textbf{Precisi\'on} & \textbf{Recobrado} & \textbf{F1} & \textbf{Exactitud}\\
%         \midrule
%         \midrule
%                        {Anotaci\'on 1}      & 0.816 & 0.815 & 0.803 & 0.810\\
%                        {Anotaci\'on 2}      & 0.900 & 0.878 & 0.886 & 0.959\\
%         \bottomrule
%         \end{tabular}}
%     \caption{Resumen de m\'etricas de evaluaci\'on del \emph{baseline} humano en cuanto a la predicci\'on del atributo raza.}
%     \label{table:eval_baseline2_race}
% \end{table}


\section{Discusi\'on}
Los resultados presentados en la Tabla~\ref{table:agreement_humans} indican un alto grado de concordancia entre las 
anotaciones realizadas por los distintos anotadores humanos.

Espec\'ificamente, la concordancia entre los anotadores no expertos (\textbf{Ver.~1 - Ver.~2}) es bastante alta. La
media de las concordancias por anotaci\'on supera $0.85$ para g\'enero, raza y la uni\'on de ambas en una \'unica categor\'ia,
lo que indica un alto grado de concordancia promedio. Adem\'as, la varianza y desviaci\'on est\'andar est\'an por debajo de 
$0.11$ y $0.33$ respectivamente, lo que demuestra poca dispersi\'on en los valores de concordancia por texto. El
\emph{macro-agreement} de $0.886$, refuerza la consistencia en t\'erminos generales. Todo esto sugiere que las directrices 
de anotaci\'on fueron adecuadas y permitieron obtener anotaciones consistentes entre anotadores no expertos.

Al comparar las anotaciones de los no expertos con la versi\'on final (\textbf{Ver.~1 - Final} y \textbf{Ver.~2 - Final}), se
observa una mejor\'ia en las m\'etricas. La media supera $0.90$ en todos los casos, la varianza y desviaci\'on est\'andar
disminuyen por debajo de $0.08$ y $0.28$ respectivamente, y el \emph{macro-agreement} aumenta a $0.917$ y 
$0.962$. Esto indica que, como se esperaba, la mezcla y revisi\'on por el experto establece un 
punto medio entre ambos anotadores, evidenciando una mayor calidad y consistencia en las anotaciones.

Los resultados de la Tabla~\ref{table:agreement_gpt} muestran m\'etricas de concordancia significativamente menores entre 
el anotador autom\'atico \emph{ChatGPT} y el corpus final. La media se encuentra por debajo de $0.38$ en todos los casos,
indicando un bajo grado de coincidencia promedio. Adem\'as, la varianza supera $0.20$ en los casos de g\'enero y raza, y 
$0.12$ en la uni\'on. La desviaci\'on est\'andar supera $0.35$ en todos los casos. Todo esto indica una alta 
dispersi\'on en los valores de concordancia por texto respecto a los obtenidos por los anotadores humanos. El 
\emph{macro-agreement} de apenas $0.361$ evidencia la falta de consistencia del anotador autom\'atico. En conjunto, estas
m\'etricas proveen evidencia de que un anotador autom\'atico de prop\'osito general como \emph{ChatGPT} no es capaz de replicar
de manera confiable las anotaciones realizadas por los anotadores humanos.  

Analizando los resultados mostrados en la Tabla~\ref{table:eval_baselines_gender} para la predicci\'on de g\'enero con el 
\emph{baseline} de aprendizaje autom\'atico se observa que la exactitud alcanza valores hasta de $0.404$, 
evidenciando una capacidad moderada del clasificador para acertar en la predicci\'on de g\'enero. La precisi\'on se 
mantuvo en un rango entre $0.617$ y $0.743$ para todos los modelos, lo cual sugiere que estos no
clasifican demasiados falsos positivos. Las puntuaciones de recobrado fueron en general altas, superando $0.718$
en la mayor\'ia de los casos. Esto indica que los modelos en general clasifican bien las intancias positivas. Luego, las 
puntuaciones $F_1$ se mantuvieron en un rango entre $0.689$ y $0.764$, demostrando que se logra
un balance bastante aceptable entre precisi\'on y recobrado.%A lo mejor se puede decir algo mejor que bastante aceptable

En contraste, los resultados para la predicci\'on de raza (Tabla~\ref{table:eval_baselines_race}) con el 
\emph{baseline} de aprendizaje autom\'atico muestran m\'etricas considerablemente m\'as bajas. Tanto la 
precisi\'on como el recobrado de los modelos se mantuvieron por debajo de $0.190$, y en consecuencia 
las puntuaciones $F_1$ no superan $0.180$. Todo esto evidencia de manera consistente que los modelos no 
logran clasificar correctamente las instancias positivas. Los valores para la exactitud no superan el puntanje 
de $0.205$. 

Estas diferencias tan marcadas en las m\'etricas de g\'enero y raza sugieren que predecir autom\'aticamente la 
raza a partir de texto representa un desaf\'io significativamente mayor en comparaci\'on con la predicci\'on de 
g\'enero. 

Las m\'etricas obtenidas para el \emph{baseline} humano, mostradas en las 
Tablas~\ref{table:eval_baselines_gender} y~\ref{table:eval_baselines_race}, indican un desempe\~no muy 
superior al de los modelos de aprendizaje autom\'atico. 

Para la tarea de g\'enero (Tabla~\ref{table:eval_baselines_gender}), todos los valores alcanzados
por las m\'etricas superan $0.870$ para ambos anotadores. Lo que sugiere un 
rendimiento muy consistente y preciso en la clasificaci\'on tanto de instancias positivas, 
como negativas. En general se observa un desempe\~no superior del 
\emph{baseline} humano en comparaci\'on com el \emph{baseline} de aprendizaje autom\'atico en 
esta tarea.

Del mismo modo, para la predicci\'on de la raza, los valores obtenidos en las m\'etricas calculadas son 
muy prometedores para ambos anotadores. La precisi\'on y 
recobrado alcanzada por los anotadores superan $0.810$, y la puntuaci\'on F1 estuvo 
por encima de $0.800$. La exactitud tambi\'en fue muy alta, con valores de $0.810$
y $0.959$, evidenciando la gran habilidad de los humanos para replicar las anotaciones
de raza presentes en el corpus.

A pesar de que el \emph{baseline} humano logra m\'etricas de evaluaci\'on muy altas en ambas 
tareas, se aprecia cierto aumento en la dificultad de la tarea de predicci\'on de raza. Si bien 
los resultados alcanzados en la predicci\'on de la raza son muy buenos, su disminuci\'on 
comparados con los obtenidos en la predicci\'on de g\'enero sugiere que incluso para los humanos, 
no es una tarea trivial inferir la raza a partir de texto.